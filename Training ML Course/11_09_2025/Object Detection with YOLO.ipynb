{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3757427-af5d-4636-b82e-1f59f5366e01",
   "metadata": {},
   "source": [
    "# YOLO Object Detection Demo (YOLOv8 Pre-trained)\n",
    "\n",
    "In this demo, we will:\n",
    "1. Install and load the Ultralytics YOLO library.\n",
    "2. Load a pre-trained YOLOv8 model.\n",
    "3. Run object detection on sample images.\n",
    "4. Visualize predictions with bounding boxes and class labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e985de-ad45-4e1a-8879-2f94388b9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics\n",
    "!pip install ultralytics --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d480173-4a0c-422f-9deb-2cced4c28862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import YOLO\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125c3a7-9fa2-4427-adb2-ad240327fa1e",
   "metadata": {},
   "source": [
    "## Load Pre-trained YOLOv8 Model\n",
    "We use YOLOv8s (small) trained on COCO dataset with 80 classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483520c0-fb45-412e-9f7f-65984cfe3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 small model\n",
    "model = YOLO(\"yolov8s.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57e8c4b-5e08-40b5-a3b3-dcb40e617a4b",
   "metadata": {},
   "source": [
    "## Run Inference on Sample Images\n",
    "We can try:\n",
    "- A street scene (cars, people, bikes)\n",
    "- An indoor image (objects like chair, laptop, bottle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ff1e62-19f6-4021-9cfb-ecb56a1d356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\saakh\\Learning\\AI_ML\\Data_Analyst_Bootcamp\\PythonBasic\\Training ML Course\\11_09_2025\\bus.jpg: 640x480 4 persons, 1 bus, 237.1ms\n",
      "Speed: 31.3ms preprocess, 237.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "# Download a test image (you can replace with local image paths)\n",
    "#!wget -q https://ultralytics.com/images/bus.jpg -O bus.jpg\n",
    "#!wget -q https://ultralytics.com/images/zidane.jpg -O zidane.jpg\n",
    "\n",
    "# Run inference\n",
    "results1 = model(\"bus.jpg\")\n",
    "#results2 = model(\"zidane.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8718b881-a0c4-4bfa-aac0-7a44a8b59fcc",
   "metadata": {},
   "source": [
    "## Visualize Predictions\n",
    "YOLO automatically saves annotated images in `runs/detect/predict`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cac7643-bfb2-4b85-a422-f792644f7924",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Extract original and annotated images\n",
    "orig_img = results1[0].orig_img              # original image (BGR format)\n",
    "annotated_img = results1[0].plot()           # YOLO’s annotated output (BGR format)\n",
    "\n",
    "# Convert BGR → RGB for matplotlib\n",
    "orig_img_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Plot side by side\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(orig_img_rgb)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(annotated_img_rgb)\n",
    "plt.title(\"YOLOv8 Detection\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7026ff-2c7b-4b5c-b478-429f912d73b5",
   "metadata": {},
   "source": [
    "# Key Takeaways\n",
    "- YOLO (You Only Look Once) performs **real-time object detection**.\n",
    "- The model predicts **both class labels and bounding boxes**.\n",
    "- Pre-trained YOLO models can be directly used for inference.\n",
    "- For custom tasks (like detecting specific objects), YOLO can be **fine-tuned** on your dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3b31a-d275-421d-8ac4-577ae3c491db",
   "metadata": {},
   "source": [
    "## Optional: Object Detection on live video feed\n",
    "- It will not work in our lab, works only locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67af57-3ed0-4be3-b46c-06bf03594c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics YOLO\n",
    "!pip install ultralytics opencv-python --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109e91d-803d-495c-a603-7a5556ce924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model (small version for speed)\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "# Open webcam (0 = default camera, change index if needed)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run YOLO inference\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    # Annotated frame (YOLO returns list of results, take first)\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow(\"YOLOv8 Webcam Detection\", annotated_frame)\n",
    "    \n",
    "    # Break on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
